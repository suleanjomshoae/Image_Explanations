# Context-based Image Explanations for Deep Neural Networks

This repository contains MATLAB implementation of context based image explanations for DNNs. We implement partial masking on segmented components to identify the contextual importance of each segment in scene classification tasks. We then generate explanations based on feature importance. We present visual and text-based explanations as: 

* Saliency map presents the pertinent components with a descriptive textual justification.

* Visual map with a color bar graph showing the relative importance of each feature for a prediction.

### Visual Explanations

<img src="https://user-images.githubusercontent.com/90247778/133998757-53621966-df7a-4e2a-bd23-cda71746ce9e.png" width=50% height=50%>

### Saliency Map and Text-based Explanations

<img src="https://user-images.githubusercontent.com/90247778/133999224-a4d487c2-3faf-4d1d-9183-6ebaaa2d18bf.png" width=50% height=50%>

